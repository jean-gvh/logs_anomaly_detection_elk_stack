{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Détection d'anomalies dans les logs système\n",
        "\n",
        "## Introduction et justification du modèle\n",
        "\n",
        "Ce notebook implémente un système de détection d'anomalies dans les logs système en utilisant l'algorithme Isolation Forest. Le choix de cet algorithme est justifié par plusieurs raisons :\n",
        "\n",
        "1. **Non-supervisé** : Isolation Forest ne nécessite pas de données étiquetées, ce qui est idéal pour la détection d'anomalies dans les logs où les exemples d'anomalies sont rares.\n",
        "\n",
        "2. **Scalabilité** : L'algorithme a une complexité temporelle linéaire et peut gérer de grands volumes de données efficacement grâce à son approche par sous-échantillonnage.\n",
        "\n",
        "3. **Robustesse aux données haute dimension** : Après le one-hot encoding, nos données ont une très haute dimensionnalité. Isolation Forest reste efficace dans ce contexte.\n",
        "\n",
        "4. **Efficacité** : L'algorithme est particulièrement efficace pour détecter les anomalies car il se base sur le principe que les anomalies sont plus faciles à isoler que les observations normales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libs"
      },
      "outputs": [],
      "source": [
        "# Import des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse exploratoire des données\n",
        "\n",
        "Avant de procéder au traitement des données et à l'entraînement du modèle, il est important d'analyser nos données pour mieux comprendre leur structure et leurs caractéristiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_analysis"
      },
      "outputs": [],
      "source": [
        "def analyze_data(df):\n",
        "    print(\"Analyse exploratoire des données:\")\n",
        "    print(\"\\nDimensionalité des données:\")\n",
        "    print(f\"Nombre de lignes: {df.shape[0]}\")\n",
        "    print(f\"Nombre de colonnes: {df.shape[1]}\")\n",
        "    \n",
        "    print(\"\\nDistribution des processus:\")\n",
        "    process_dist = df['Process'].value_counts()\n",
        "    print(process_dist.head())\n",
        "    \n",
        "    print(\"\\nDistribution des hosts:\")\n",
        "    host_dist = df['Hostname'].value_counts()\n",
        "    print(host_dist.head())\n",
        "    \n",
        "    # Visualisation de la distribution des processus\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    process_dist.head(10).plot(kind='bar')\n",
        "    plt.title('Top 10 des processus les plus fréquents')\n",
        "    plt.xlabel('Processus')\n",
        "    plt.ylabel('Nombre d\\'occurrences')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Chargement et analyse des données\n",
        "print(\"Chargement du fichier CSV...\")\n",
        "df = pd.read_csv(\"all_logs.csv\")\n",
        "analyze_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prétraitement des données\n",
        "\n",
        "Cette section comprend le nettoyage des données et l'encodage one-hot des variables catégorielles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing"
      },
      "outputs": [],
      "source": [
        "# Nettoyage des données\n",
        "print(\"Vérification des valeurs nulles avant suppression :\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nSuppression des lignes avec des valeurs nulles...\")\n",
        "df_cleaned = df.dropna()\n",
        "\n",
        "print(f\"\\nNombre de lignes après suppression des valeurs nulles : {len(df_cleaned)}\")\n",
        "\n",
        "# Conversion des types\n",
        "df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]] = \\\n",
        "    df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]].astype(str)\n",
        "\n",
        "# One-hot encoding\n",
        "print(\"\\nApplication du One-Hot Encoding...\")\n",
        "df_encoded = pd.get_dummies(df_cleaned, columns=[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"])\n",
        "print(f\"Le DataFrame encodé contient désormais {df_encoded.shape[1]} colonnes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fonctions d'évaluation du modèle\n",
        "\n",
        "Ces fonctions permettent d'évaluer les performances du modèle et d'analyser les anomalies détectées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluation_functions"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, contamination=0.1):\n",
        "    # Prédictions sur le jeu de test\n",
        "    predictions = model.predict(X_test)\n",
        "    \n",
        "    # Convertir les prédictions (-1: anomalie, 1: normal) en format binaire\n",
        "    predictions_binary = np.where(predictions == -1, 1, 0)\n",
        "    \n",
        "    # Créer un \"ground truth\" synthétique basé sur les scores d'anomalie\n",
        "    scores = -model.score_samples(X_test)\n",
        "    threshold = np.percentile(scores, (1 - contamination) * 100)\n",
        "    ground_truth = np.where(scores > threshold, 1, 0)\n",
        "    \n",
        "    # Calculer les métriques\n",
        "    precision = precision_score(ground_truth, predictions_binary)\n",
        "    recall = recall_score(ground_truth, predictions_binary)\n",
        "    f1 = f1_score(ground_truth, predictions_binary)\n",
        "    \n",
        "    print(\"\\nÉvaluation du modèle:\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall: {recall:.3f}\")\n",
        "    print(f\"F1-score: {f1:.3f}\")\n",
        "    \n",
        "    # Visualisation des scores d'anomalie\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(scores, bins=50)\n",
        "    plt.axvline(x=threshold, color='r', linestyle='--', label='Seuil d\\'anomalie')\n",
        "    plt.title('Distribution des scores d\\'anomalie')\n",
        "    plt.xlabel('Score d\\'anomalie')\n",
        "    plt.ylabel('Nombre d\\'observations')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return predictions_binary, scores\n",
        "\n",
        "def analyze_anomalies(df_original, predictions, scores):\n",
        "    df_anomalies = df_original.copy()\n",
        "    df_anomalies['anomaly_score'] = scores\n",
        "    df_anomalies['is_anomaly'] = predictions\n",
        "    \n",
        "    print(\"\\nAnalyse des anomalies détectées:\")\n",
        "    print(f\"Nombre total d'anomalies: {predictions.sum()}\")\n",
        "    print(\"\\nExemples d'anomalies détectées (top 5 par score):\")\n",
        "    anomalies = df_anomalies[df_anomalies['is_anomaly'] == 1].sort_values('anomaly_score', ascending=False)\n",
        "    print(anomalies[['Date', 'Hostname', 'Process', 'Message', 'anomaly_score']].head())\n",
        "    \n",
        "    # Visualisation des anomalies par host\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    anomalies['Hostname'].value_counts().head(10).plot(kind='bar')\n",
        "    plt.title('Distribution des anomalies par host')\n",
        "    plt.xlabel('Hostname')\n",
        "    plt.ylabel('Nombre d\\'anomalies')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entraînement du modèle\n",
        "\n",
        "Cette section comprend la séparation des données, l'entraînement du modèle et son évaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_training"
      },
      "outputs": [],
      "source": [
        "# Séparation des données\n",
        "print(\"Séparation des données...\")\n",
        "X_train, X_test = train_test_split(df_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Configuration et entraînement du modèle\n",
        "print(\"\\nEntraînement du modèle...\")\n",
        "model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    contamination='auto',\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train)\n",
        "\n",
        "# Évaluation du modèle\n",
        "predictions, scores = evaluate_model(model, X_test)\n",
        "analyze_anomalies(df_cleaned.loc[X_test.index], predictions, scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sauvegarde du modèle\n",
        "\n",
        "Sauvegarde du modèle entraîné et de ses métadonnées pour une utilisation future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_saving"
      },
      "outputs": [],
      "source": [
        "# Sauvegarde du modèle et des métadonnées\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_filename = f'isolation_forest_model_{timestamp}.joblib'\n",
        "metadata_filename = f'model_metadata_{timestamp}.json'\n",
        "\n",
        "# Création des métadonnées\n",
        "metadata = {\n",
        "    'date_entrainement': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    'nombre_lignes': len(df),\n",
        "    'nombre_colonnes_encodees': df_encoded.shape[1],\n",
        "    'parametres_model': {\n",
        "        'n_estimators': 100,\n",
        "        'contamination': 'auto'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Sauvegarde\n",
        "joblib.dump(model, model_filename)\n",
        "with open(metadata_filename, 'w') as f:\n",
        "    json.dump(metadata, f)\n",
        "\n",
        "print(f\"\\nModèle sauvegardé: {model_filename}\")\n",
        "print(f\"Métadonnées sauvegardées: {metadata_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Ce notebook présente une implémentation complète d'un système de détection d'anomalies dans les logs système utilisant l'algorithme Isolation Forest. Les principales améliorations apportées sont :\n",
        "\n",
        "1. Une analyse exploratoire approfondie des données\n",
        "2. Une évaluation rigoureuse du modèle avec des métriques performance (précision, rappel, F1-score)\n",
        "3. Une visualisation détaillée des résultats et des anomalies détectées\n",
        "4. Un système de sauvegarde du modèle avec métadonnées\n",
        "\n",
        "### Limitations et améliorations possibles\n",
        "\n",
        "1. **Prétraitement des données**:\n",
        "   - Le one-hot encoding génère un grand nombre de features (19578 colonnes)\n",
        "   - Une réduction de dimensionnalité (PCA, UMAP) pourrait être envisagée\n",
        "   - L'utilisation de techniques de feature engineering plus avancées pour les logs (ex: TF-IDF pour les messages)\n",
        "\n",
        "2. **Modélisation**:\n",
        "   - Tester d'autres algorithmes de détection d'anomalies (DBSCAN, LOF, auto-encoders)\n",
        "   - Optimiser les hyperparamètres via validation croisée\n",
        "   - Implémenter une approche ensembliste combinant plusieurs modèles\n",
        "\n",
        "3. **Évaluation**:\n",
        "   - Créer un jeu de données étiqueté pour une validation plus rigoureuse\n",
        "   - Implémenter une évaluation en temps réel\n",
        "   - Ajouter des métriques spécifiques au domaine des logs\n",
        "\n",
        "4. **Production**:\n",
        "   - Ajouter un système de monitoring des performances du modèle\n",
        "   - Implémenter une stratégie de réentraînement périodique\n",
        "   - Optimiser le pipeline pour le traitement en temps réel\n",
        "\n",
        "### Perspectives\n",
        "\n",
        "Ce système pourrait être étendu pour :\n",
        "1. Détecter des patterns d'anomalies spécifiques\n",
        "2. Intégrer des règles métier pour la classification des anomalies\n",
        "3. Générer des alertes automatiques avec différents niveaux de criticité\n",
        "4. S'adapter automatiquement aux changements de patterns dans les logs\n",
        "\n",
        "Le code source est disponible pour toute amélioration ou adaptation à des besoins spécifiques."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
