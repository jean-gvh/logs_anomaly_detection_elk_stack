{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "0PEVpW0lPK0A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **One-Hot Encoding des logs**"
      ],
      "metadata": {
        "id": "JTjosdA7QNrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Chargement du fichier CSV...\")\n",
        "df = pd.read_csv(\"all_logs.csv\")\n",
        "print(f\"Fichier chargé avec {len(df)} lignes et {df.shape[1]} colonnes.\")\n",
        "\n",
        "print(\"Vérification des valeurs nulles avant suppression :\")\n",
        "print(df.isnull().sum())  # Affiche le nombre de valeurs nulles par colonne\n",
        "print(\"Suppression des lignes avec des valeurs nulles...\")\n",
        "df_cleaned = df.dropna()  # Supprime toutes les lignes contenant des NaN\n",
        "\n",
        "print(f\"Nombre de lignes après suppression des valeurs nulles : {len(df_cleaned)}\")\n",
        "\n",
        "print(\"Vérification des valeurs nulles après suppression :\")\n",
        "print(df_cleaned.isnull().sum())  # Affiche le nombre de valeurs nulles par colonne\n",
        "\n",
        "print(\"Vérification des types des colonnes après conversion :\")\n",
        "df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]] = df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]].astype(str)\n",
        "print(df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]].dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYSRF6KPNAp",
        "outputId": "e9acc67a-f8ac-44b1-9566-edf88e3e77c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement du fichier CSV...\n",
            "Fichier chargé avec 162046 lignes et 5 colonnes.\n",
            "Vérification des valeurs nulles avant suppression :\n",
            "Date         29350\n",
            "Hostname     29350\n",
            "Process      29350\n",
            "IdProcess    94758\n",
            "Message      29350\n",
            "dtype: int64\n",
            "Suppression des lignes avec des valeurs nulles...\n",
            "Nombre de lignes après suppression des valeurs nulles : 67288\n",
            "Vérification des valeurs nulles après suppression :\n",
            "Date         0\n",
            "Hostname     0\n",
            "Process      0\n",
            "IdProcess    0\n",
            "Message      0\n",
            "dtype: int64\n",
            "Vérification des types des colonnes après conversion :\n",
            "Date         object\n",
            "Hostname     object\n",
            "Process      object\n",
            "IdProcess    object\n",
            "Message      object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-07f9318208bc>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]] = df_cleaned[[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"]].astype(str)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliquer le One-Hot Encoding à l'aide de pandas.get_dummies\n",
        "print(\"Application du One-Hot Encoding...\")\n",
        "df_encoded = pd.get_dummies(df_cleaned, columns=[\"Date\", \"Hostname\", \"Process\", \"IdProcess\", \"Message\"])\n",
        "\n",
        "# Afficher le nombre de colonnes après l'encodage\n",
        "print(f\"Le DataFrame encodé contient désormais {df_encoded.shape[1]} colonnes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp1FVaNuPR6h",
        "outputId": "0409b7dd-7329-44b0-9034-894cf3ecf3e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Application du One-Hot Encoding...\n",
            "Le DataFrame encodé contient désormais 19578 colonnes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrainement du modèle**"
      ],
      "metadata": {
        "id": "CT6QGjJoQY4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramètres pour l'entraînement par batch\n",
        "batch_size = 1000  # Taille du lot (par exemple, 1000 lignes par lot)\n",
        "n_batches = len(df_encoded) // batch_size  # Nombre de lots\n",
        "n_estimators = 50  # Nombre d'arbres pour Isolation Forest"
      ],
      "metadata": {
        "id": "L0kO89x0VZE_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiser le modèle Isolation Forest avec contamination=\"auto\"\n",
        "train_data, test_data = train_test_split(df_encoded, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
        "model = IsolationForest(n_estimators=n_estimators, contamination=\"auto\", random_state=42)\n",
        "\n",
        "\n",
        "# Initialiser le modèle Isolation Forest avec contamination=\"auto\"\n",
        "model = IsolationForest(n_estimators=n_estimators, contamination=\"auto\", random_state=42)\n",
        "\n",
        "# Mélanger les indices du DataFrame de façon aléatoire pour l'entraînement\n",
        "train_indices = np.random.permutation(len(train_data))"
      ],
      "metadata": {
        "id": "uD3Die7ff-Tu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement du modèle sur chaque lot d'entraînement\n",
        "print(\"Entraînement du modèle sur chaque batch du jeu d'entraînement...\")\n",
        "n_batches_train = len(train_data) // batch_size  # Nombre de lots d'entraînement\n",
        "for i in range(n_batches_train):\n",
        "    # Extraire un lot de données aléatoires\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_indices = train_indices[start_idx:end_idx]\n",
        "    batch = train_data.iloc[batch_indices]\n",
        "\n",
        "    # Entraîner le modèle sur le lot\n",
        "    model.fit(batch)\n",
        "\n",
        "    # Afficher l'état d'avancement\n",
        "    print(f\"Batch {i + 1}/{n_batches_train} du jeu d'entraînement traité.\")\n",
        "\n",
        "# Si les données d'entraînement ne sont pas divisibles par batch_size, traiter le dernier lot restant\n",
        "if len(train_data) % batch_size != 0:\n",
        "    batch_indices = train_indices[n_batches_train * batch_size:]\n",
        "    batch = train_data.iloc[batch_indices]\n",
        "    model.fit(batch)\n",
        "    print(f\"Dernier batch du jeu d'entraînement traité.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZCU06qfgxrY",
        "outputId": "7c5cff67-679f-4276-df2f-dae38e31a77d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entraînement du modèle sur chaque batch du jeu d'entraînement...\n",
            "Batch 1/53 du jeu d'entraînement traité.\n",
            "Batch 2/53 du jeu d'entraînement traité.\n",
            "Batch 3/53 du jeu d'entraînement traité.\n",
            "Batch 4/53 du jeu d'entraînement traité.\n",
            "Batch 5/53 du jeu d'entraînement traité.\n",
            "Batch 6/53 du jeu d'entraînement traité.\n",
            "Batch 7/53 du jeu d'entraînement traité.\n",
            "Batch 8/53 du jeu d'entraînement traité.\n",
            "Batch 9/53 du jeu d'entraînement traité.\n",
            "Batch 10/53 du jeu d'entraînement traité.\n",
            "Batch 11/53 du jeu d'entraînement traité.\n",
            "Batch 12/53 du jeu d'entraînement traité.\n",
            "Batch 13/53 du jeu d'entraînement traité.\n",
            "Batch 14/53 du jeu d'entraînement traité.\n",
            "Batch 15/53 du jeu d'entraînement traité.\n",
            "Batch 16/53 du jeu d'entraînement traité.\n",
            "Batch 17/53 du jeu d'entraînement traité.\n",
            "Batch 18/53 du jeu d'entraînement traité.\n",
            "Batch 19/53 du jeu d'entraînement traité.\n",
            "Batch 20/53 du jeu d'entraînement traité.\n",
            "Batch 21/53 du jeu d'entraînement traité.\n",
            "Batch 22/53 du jeu d'entraînement traité.\n",
            "Batch 23/53 du jeu d'entraînement traité.\n",
            "Batch 24/53 du jeu d'entraînement traité.\n",
            "Batch 25/53 du jeu d'entraînement traité.\n",
            "Batch 26/53 du jeu d'entraînement traité.\n",
            "Batch 27/53 du jeu d'entraînement traité.\n",
            "Batch 28/53 du jeu d'entraînement traité.\n",
            "Batch 29/53 du jeu d'entraînement traité.\n",
            "Batch 30/53 du jeu d'entraînement traité.\n",
            "Batch 31/53 du jeu d'entraînement traité.\n",
            "Batch 32/53 du jeu d'entraînement traité.\n",
            "Batch 33/53 du jeu d'entraînement traité.\n",
            "Batch 34/53 du jeu d'entraînement traité.\n",
            "Batch 35/53 du jeu d'entraînement traité.\n",
            "Batch 36/53 du jeu d'entraînement traité.\n",
            "Batch 37/53 du jeu d'entraînement traité.\n",
            "Batch 38/53 du jeu d'entraînement traité.\n",
            "Batch 39/53 du jeu d'entraînement traité.\n",
            "Batch 40/53 du jeu d'entraînement traité.\n",
            "Batch 41/53 du jeu d'entraînement traité.\n",
            "Batch 42/53 du jeu d'entraînement traité.\n",
            "Batch 43/53 du jeu d'entraînement traité.\n",
            "Batch 44/53 du jeu d'entraînement traité.\n",
            "Batch 45/53 du jeu d'entraînement traité.\n",
            "Batch 46/53 du jeu d'entraînement traité.\n",
            "Batch 47/53 du jeu d'entraînement traité.\n",
            "Batch 48/53 du jeu d'entraînement traité.\n",
            "Batch 49/53 du jeu d'entraînement traité.\n",
            "Batch 50/53 du jeu d'entraînement traité.\n",
            "Batch 51/53 du jeu d'entraînement traité.\n",
            "Batch 52/53 du jeu d'entraînement traité.\n",
            "Batch 53/53 du jeu d'entraînement traité.\n",
            "Dernier batch du jeu d'entraînement traité.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédiction sur le jeu de test\n",
        "print(\"Prédiction des anomalies sur le jeu de test...\")\n",
        "y_pred_test = np.zeros(len(test_data), dtype=int)\n",
        "\n",
        "# Mélanger les indices du DataFrame de test\n",
        "test_indices = np.random.permutation(len(test_data))\n",
        "\n",
        "# Prédiction incrémentale sur les données de test\n",
        "n_batches_test = len(test_data) // batch_size  # Nombre de lots de test\n",
        "for i in range(n_batches_test):\n",
        "    # Extraire un lot de données aléatoires\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_indices = test_indices[start_idx:end_idx]\n",
        "    batch = test_data.iloc[batch_indices]\n",
        "\n",
        "    # Prédiction pour le lot actuel\n",
        "    batch_pred = model.predict(batch)\n",
        "\n",
        "    # Convertir les prédictions : -1 signifie anomalie, 1 signifie normal\n",
        "    batch_pred = np.where(batch_pred == -1, 1, 0)\n",
        "\n",
        "    # Ajouter les prédictions au tableau y_pred_test\n",
        "    y_pred_test[start_idx:end_idx] = batch_pred\n",
        "\n",
        "    print(f\"Batch {i + 1}/{n_batches_test} du jeu de test prédit.\")\n",
        "\n",
        "# Si les données de test ne sont pas divisibles par batch_size, traiter le dernier lot restant\n",
        "if len(test_data) % batch_size != 0:\n",
        "    batch_indices = test_indices[n_batches_test * batch_size:]\n",
        "    batch = test_data.iloc[batch_indices]\n",
        "    batch_pred = model.predict(batch)\n",
        "    batch_pred = np.where(batch_pred == -1, 1, 0)\n",
        "    y_pred_test[n_batches_test * batch_size:] = batch_pred\n",
        "    print(f\"Dernière prédiction du batch du jeu de test effectuée.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95vJ90Jrg3Bl",
        "outputId": "828131ac-6325-4340-b1b0-6d51e4123745"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction des anomalies sur le jeu de test...\n",
            "Batch 1/13 du jeu de test prédit.\n",
            "Batch 2/13 du jeu de test prédit.\n",
            "Batch 3/13 du jeu de test prédit.\n",
            "Batch 4/13 du jeu de test prédit.\n",
            "Batch 5/13 du jeu de test prédit.\n",
            "Batch 6/13 du jeu de test prédit.\n",
            "Batch 7/13 du jeu de test prédit.\n",
            "Batch 8/13 du jeu de test prédit.\n",
            "Batch 9/13 du jeu de test prédit.\n",
            "Batch 10/13 du jeu de test prédit.\n",
            "Batch 11/13 du jeu de test prédit.\n",
            "Batch 12/13 du jeu de test prédit.\n",
            "Batch 13/13 du jeu de test prédit.\n",
            "Dernière prédiction du batch du jeu de test effectuée.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajouter les prédictions au DataFrame de test\n",
        "test_data[\"Anomaly\"] = y_pred_test\n",
        "\n",
        "# Afficher les anomalies détectées sur le jeu de test\n",
        "anomalies_detectees = np.sum(y_pred_test)  # Compte le nombre d'anomalies (1 signifie anomalie)\n",
        "print(f\"Nombre d'anomalies détectées dans le jeu de test : {anomalies_detectees}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmxI8zfYg6gf",
        "outputId": "91e642de-1edc-424a-e7a4-a7e4123449ad"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'anomalies détectées dans le jeu de test : 0\n"
          ]
        }
      ]
    }
  ]
}